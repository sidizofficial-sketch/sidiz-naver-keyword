import streamlit as st
import pandas as pd
import time
import hashlib
import hmac
import base64
import requests
import plotly.express as px
from datetime import datetime

# --- 1. ë„¤ì´ë²„ API ì¸ì¦ ë° í˜¸ì¶œ í•¨ìˆ˜ (ì•ˆì •ì„± ê°•í™”) ---
def generate_signature(timestamp, method, uri, secret_key):
    message = f"{timestamp}.{method}.{uri}"
    hash = hmac.new(bytes(secret_key, "utf-8"), bytes(message, "utf-8"), hashlib.sha256)
    return base64.b64encode(hash.digest()).decode()

def get_naver_search_vols_bulk(keywords, api_key, secret_key, customer_id):
    BASE_URL = 'https://api.searchad.naver.com'
    uri = '/keywordstool'
    method = 'GET'
    timestamp = str(round(time.time() * 1000))
    signature = generate_signature(timestamp, method, uri, secret_key)
    headers = {
        'X-Timestamp': timestamp, 
        'X-API-KEY': api_key, 
        'X-Customer': customer_id, 
        'X-Signature': signature
    }
    params = {
        'hintKeywords': ",".join(keywords[:5]), 
        'showDetail': '1'
    }
    vols = {}
    try:
        res = requests.get(BASE_URL + uri, params=params, headers=headers, timeout=10)
        res.raise_for_status()  # HTTP ì˜¤ë¥˜ í™•ì¸
        data = res.json()
        
        if 'keywordList' in data:
            for item in data['keywordList']:
                pc = str(item.get('monthlyPcQcCnt', '0')).replace('< ', '')
                mo = str(item.get('monthlyMobileQcCnt', '0')).replace('< ', '')
                try:
                    total = int(pc) + int(mo)
                except ValueError:
                    total = 0
                vols[item['relKeyword']] = total
    except requests.exceptions.RequestException as e:
        st.warning(f"ê²€ìƒ‰ëŸ‰ API ì˜¤ë¥˜: {str(e)}")
    except Exception as e:
        st.warning(f"ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    return vols

def get_datalab_trend(keyword, client_id, client_secret, start_date, end_date, time_unit):
    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {
        "X-Naver-Client-Id": client_id, 
        "X-Naver-Client-Secret": client_secret, 
        "Content-Type": "application/json"
    }
    unit_map = {"ì¼ìë³„": "date", "ì£¼ì°¨ë³„": "week", "ì›”ë³„": "month"}
    body = {
        "startDate": start_date.strftime("%Y-%m-%d"),
        "endDate": end_date.strftime("%Y-%m-%d"),
        "timeUnit": unit_map.get(time_unit, "month"),
        "keywordGroups": [{"groupName": keyword, "keywords": [keyword]}]
    }
    try:
        res = requests.post(url, headers=headers, json=body, timeout=10)
        res.raise_for_status()
        data = res.json()
        
        if 'results' in data and len(data['results']) > 0 and 'data' in data['results'][0]:
            return {d['period']: d['ratio'] for d in data['results'][0]['data']}
    except requests.exceptions.RequestException as e:
        st.warning(f"íŠ¸ë Œë“œ API ì˜¤ë¥˜ ({keyword}): {str(e)}")
    except Exception as e:
        st.warning(f"íŠ¸ë Œë“œ ì²˜ë¦¬ ì˜¤ë¥˜ ({keyword}): {str(e)}")
    
    return {}

# --- 2. ë°ì´í„° ë¡œë”© ---
@st.cache_data(ttl=600)
def load_all_data(sheet_id):
    try:
        main_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv"
        m_df = pd.read_csv(main_url)
        m_df.columns = [c.strip().upper() for c in m_df.columns]
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        if 'GROUP' not in m_df.columns or 'KEYWORD' not in m_df.columns:
            st.error(f"ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— 'GROUP', 'KEYWORD' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {m_df.columns.tolist()}")
            return pd.DataFrame(), {}
        
    except Exception as e:
        st.error(f"ë©”ì¸ ì‹œíŠ¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        return pd.DataFrame(), {}
    
    # í”„ë¦¬ì…‹ ë¡œë”©
    presets = {}
    try:
        preset_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet=PRESETS"
        p_df = pd.read_csv(preset_url)
        p_df.columns = [c.strip().upper() for c in p_df.columns]
        
        name_col = next((c for c in p_df.columns if 'NAME' in c), None)
        kw_col = next((c for c in p_df.columns if 'KEYWORD' in c), None)
        
        if name_col and kw_col:
            for _, row in p_df.iterrows():
                name = str(row[name_col]).strip()
                keywords = str(row[kw_col]).strip()
                if name and keywords and name != 'nan' and keywords != 'nan':
                    presets[name] = [k.strip() for k in keywords.split(',') if k.strip()]
    except Exception as e:
        st.info(f"í”„ë¦¬ì…‹ ì‹œíŠ¸ê°€ ì—†ê±°ë‚˜ ë¡œë”© ì‹¤íŒ¨ (ì„ íƒì‚¬í•­): {str(e)}")
    
    return m_df, presets

# --- 3. UI ë° ì„¤ì • ---
st.set_page_config(page_title="ì‹œë””ì¦ˆ ë§ˆì¼€íŒ… ëŒ€ì‹œë³´ë“œ", layout="wide")

# Secrets í™•ì¸
try:
    required_keys = ["NAVER_API_KEY", "NAVER_SECRET_KEY", "NAVER_CUSTOMER_ID", 
                     "NAVER_CLIENT_ID", "NAVER_CLIENT_SECRET"]
    keys = {k.lower(): st.secrets[k] for k in required_keys}
except KeyError as e:
    st.error(f"Secrets ì„¤ì • ëˆ„ë½: {str(e)}")
    st.info("Settings > Secretsì—ì„œ ë‹¤ìŒ í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”: " + ", ".join(required_keys))
    st.stop()
except Exception as e:
    st.error(f"Secrets ì„¤ì • ì˜¤ë¥˜: {str(e)}")
    st.stop()

with st.sidebar:
    st.header("âš™ï¸ ê¸°ë³¸ ì„¤ì •")
    sid = st.text_input("Sheet ID", "1JnEKEe7HDbN5NG8l0kZ55Rtihp9SBbauD0CzhKQX-qM")
    unit = st.radio("ì§‘ê³„ ë‹¨ìœ„", ["ì¼ìë³„", "ì£¼ì°¨ë³„", "ì›”ë³„"], index=2)
    s_date = st.date_input("ì‹œì‘ì¼", datetime(2024, 12, 1))
    e_date = st.date_input("ì¢…ë£Œì¼", datetime(2025, 1, 31))
    
    if s_date >= e_date:
        st.error("ì‹œì‘ì¼ì€ ì¢…ë£Œì¼ë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤")
    
    if st.button("ğŸ”„ ì „ì²´ ìƒˆë¡œê³ ì¹¨"): 
        st.cache_data.clear()
        st.rerun()

# ë°ì´í„° ë¡œë”©
master_df, presets = load_all_data(sid)

if master_df.empty:
    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Sheet IDì™€ ì‹œíŠ¸ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
if 'active_groups' not in st.session_state: 
    st.session_state.active_groups = {}
if 'num_targets' not in st.session_state: 
    st.session_state.num_targets = 2

st.title("ğŸ“Š ì‹œë¦¬ì¦ˆë³„ ë§ˆì¼“ì‰ì–´ ìƒì„¸ ë¶„ì„")

# --- 4. í”„ë¦¬ì…‹ ë²„íŠ¼ ---
if presets:
    st.subheader("âš¡ í€µ í”„ë¦¬ì…‹")
    p_cols = st.columns(min(len(presets), 5))
    for i, (name, items) in enumerate(presets.items()):
        with p_cols[i % 5]:
            if st.button(name, key=f"p_{i}", use_container_width=True):
                matched = master_df[
                    master_df['GROUP'].isin(items) | master_df['KEYWORD'].isin(items)
                ]
                st.session_state.num_targets = 1
                st.session_state.active_groups = {
                    "label_0": name,
                    "groups_0": matched['GROUP'].unique().tolist(),
                    "kws_0": matched['KEYWORD'].unique().tolist()
                }
                st.rerun()

st.markdown("---")

import streamlit as st
import pandas as pd
import time
import hashlib
import hmac
import base64
import requests
import plotly.express as px
from datetime import datetime

# --- 1. ë„¤ì´ë²„ API ì¸ì¦ ë° í˜¸ì¶œ í•¨ìˆ˜ (ì•ˆì •ì„± ê°•í™”) ---
def generate_signature(timestamp, method, uri, secret_key):
    message = f"{timestamp}.{method}.{uri}"
    hash = hmac.new(bytes(secret_key, "utf-8"), bytes(message, "utf-8"), hashlib.sha256)
    return base64.b64encode(hash.digest()).decode()

def get_naver_search_vols_bulk(keywords, api_key, secret_key, customer_id):
    BASE_URL = 'https://api.searchad.naver.com'
    uri = '/keywordstool'
    method = 'GET'
    timestamp = str(round(time.time() * 1000))
    signature = generate_signature(timestamp, method, uri, secret_key)
    headers = {
        'X-Timestamp': timestamp, 
        'X-API-KEY': api_key, 
        'X-Customer': customer_id, 
        'X-Signature': signature
    }
    params = {
        'hintKeywords': ",".join(keywords[:5]), 
        'showDetail': '1'
    }
    vols = {}
    try:
        res = requests.get(BASE_URL + uri, params=params, headers=headers, timeout=10)
        res.raise_for_status()
        data = res.json()
        
        if 'keywordList' in data:
            for item in data['keywordList']:
                pc = str(item.get('monthlyPcQcCnt', '0')).replace('< ', '')
                mo = str(item.get('monthlyMobileQcCnt', '0')).replace('< ', '')
                try:
                    total = int(pc) + int(mo)
                except ValueError:
                    total = 0
                vols[item['relKeyword']] = total
    except requests.exceptions.RequestException as e:
        st.warning(f"ê²€ìƒ‰ëŸ‰ API ì˜¤ë¥˜: {str(e)}")
    except Exception as e:
        st.warning(f"ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
    
    return vols

def get_datalab_trend(keyword, client_id, client_secret, start_date, end_date, time_unit):
    url = "https://openapi.naver.com/v1/datalab/search"
    headers = {
        "X-Naver-Client-Id": client_id, 
        "X-Naver-Client-Secret": client_secret, 
        "Content-Type": "application/json"
    }
    unit_map = {"ì¼ìë³„": "date", "ì£¼ì°¨ë³„": "week", "ì›”ë³„": "month"}
    body = {
        "startDate": start_date.strftime("%Y-%m-%d"),
        "endDate": end_date.strftime("%Y-%m-%d"),
        "timeUnit": unit_map.get(time_unit, "month"),
        "keywordGroups": [{"groupName": keyword, "keywords": [keyword]}]
    }
    try:
        res = requests.post(url, headers=headers, json=body, timeout=10)
        res.raise_for_status()
        data = res.json()
        
        if 'results' in data and len(data['results']) > 0 and 'data' in data['results'][0]:
            return {d['period']: d['ratio'] for d in data['results'][0]['data']}
    except requests.exceptions.RequestException as e:
        st.warning(f"íŠ¸ë Œë“œ API ì˜¤ë¥˜ ({keyword}): {str(e)}")
    except Exception as e:
        st.warning(f"íŠ¸ë Œë“œ ì²˜ë¦¬ ì˜¤ë¥˜ ({keyword}): {str(e)}")
    
    return {}

# --- 2. ë°ì´í„° ë¡œë”© ---
@st.cache_data(ttl=600)
def load_all_data(sheet_id):
    try:
        main_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/export?format=csv"
        m_df = pd.read_csv(main_url)
        m_df.columns = [c.strip().upper() for c in m_df.columns]
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        if 'GROUP' not in m_df.columns or 'KEYWORD' not in m_df.columns:
            st.error(f"ìŠ¤í”„ë ˆë“œì‹œíŠ¸ì— 'GROUP', 'KEYWORD' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤. í˜„ì¬ ì»¬ëŸ¼: {m_df.columns.tolist()}")
            return pd.DataFrame(), {}
        
    except Exception as e:
        st.error(f"ë©”ì¸ ì‹œíŠ¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
        return pd.DataFrame(), {}
    
    # í”„ë¦¬ì…‹ ë¡œë”©
    presets = {}
    try:
        preset_url = f"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet=PRESETS"
        p_df = pd.read_csv(preset_url)
        p_df.columns = [c.strip().upper() for c in p_df.columns]
        
        name_col = next((c for c in p_df.columns if 'NAME' in c), None)
        kw_col = next((c for c in p_df.columns if 'KEYWORD' in c), None)
        
        if name_col and kw_col:
            for _, row in p_df.iterrows():
                name = str(row[name_col]).strip()
                keywords = str(row[kw_col]).strip()
                if name and keywords and name != 'nan' and keywords != 'nan':
                    presets[name] = [k.strip() for k in keywords.split(',') if k.strip()]
    except Exception as e:
        st.info(f"í”„ë¦¬ì…‹ ì‹œíŠ¸ê°€ ì—†ê±°ë‚˜ ë¡œë”© ì‹¤íŒ¨ (ì„ íƒì‚¬í•­): {str(e)}")
    
    return m_df, presets

# --- 3. UI ë° ì„¤ì • ---
st.set_page_config(page_title="ì‹œë””ì¦ˆ ë§ˆì¼€íŒ… ëŒ€ì‹œë³´ë“œ", layout="wide")

# Secrets í™•ì¸
try:
    required_keys = ["NAVER_API_KEY", "NAVER_SECRET_KEY", "NAVER_CUSTOMER_ID", 
                     "NAVER_CLIENT_ID", "NAVER_CLIENT_SECRET"]
    keys = {k.lower(): st.secrets[k] for k in required_keys}
except KeyError as e:
    st.error(f"Secrets ì„¤ì • ëˆ„ë½: {str(e)}")
    st.info("Settings > Secretsì—ì„œ ë‹¤ìŒ í‚¤ë¥¼ ì„¤ì •í•˜ì„¸ìš”: " + ", ".join(required_keys))
    st.stop()
except Exception as e:
    st.error(f"Secrets ì„¤ì • ì˜¤ë¥˜: {str(e)}")
    st.stop()

with st.sidebar:
    st.header("âš™ï¸ ê¸°ë³¸ ì„¤ì •")
    sid = st.text_input("Sheet ID", "1JnEKEe7HDbN5NG8l0kZ55Rtihp9SBbauD0CzhKQX-qM")
    unit = st.radio("ì§‘ê³„ ë‹¨ìœ„", ["ì¼ìë³„", "ì£¼ì°¨ë³„", "ì›”ë³„"], index=2)
    s_date = st.date_input("ì‹œì‘ì¼", datetime(2024, 12, 1))
    e_date = st.date_input("ì¢…ë£Œì¼", datetime(2025, 1, 31))
    
    if s_date >= e_date:
        st.error("ì‹œì‘ì¼ì€ ì¢…ë£Œì¼ë³´ë‹¤ ì´ì „ì´ì–´ì•¼ í•©ë‹ˆë‹¤")
    
    if st.button("ğŸ”„ ì „ì²´ ìƒˆë¡œê³ ì¹¨"): 
        st.cache_data.clear()
        st.rerun()

# ë°ì´í„° ë¡œë”©
master_df, presets = load_all_data(sid)

if master_df.empty:
    st.error("ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. Sheet IDì™€ ì‹œíŠ¸ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ì„¸ì…˜ ìƒíƒœ ê´€ë¦¬
if 'active_groups' not in st.session_state: 
    st.session_state.active_groups = {}
if 'num_targets' not in st.session_state: 
    st.session_state.num_targets = 2

st.title("ğŸ“Š ì‹œë¦¬ì¦ˆë³„ ë§ˆì¼“ì‰ì–´ ìƒì„¸ ë¶„ì„")

# --- 4. í”„ë¦¬ì…‹ ë²„íŠ¼ ---
if presets:
    st.subheader("âš¡ í€µ í”„ë¦¬ì…‹")
    p_cols = st.columns(min(len(presets), 5))
    for i, (name, items) in enumerate(presets.items()):
        with p_cols[i % 5]:
            if st.button(name, key=f"p_{i}", use_container_width=True):
                matched = master_df[
                    master_df['GROUP'].isin(items) | master_df['KEYWORD'].isin(items)
                ]
                st.session_state.num_targets = 1
                st.session_state.active_groups = {
                    "label_0": name,
                    "groups_0": matched['GROUP'].unique().tolist(),
                    "kws_0": matched['KEYWORD'].unique().tolist()
                }
                st.rerun()

st.markdown("---")

# --- 5. ë¶„ì„ ëŒ€ìƒ ì„¤ì • ---
st.subheader("ğŸ› ï¸ ë¶„ì„ ëŒ€ìƒ ì„¤ì •")
num_targets = st.number_input(
    "ë¶„ì„ ëŒ€ìƒ ê°œìˆ˜", 
    min_value=1, 
    max_value=5, 
    value=st.session_state.num_targets
)
st.session_state.num_targets = num_targets

final_filter = {}
group_options = sorted([g for g in master_df['GROUP'].unique() if pd.notna(g)])

# ë””ë²„ê¹…ìš© ì •ë³´ í‘œì‹œ
with st.expander("ğŸ” ë°ì´í„° í™•ì¸ (ë””ë²„ê¹…)"):
    st.write(f"ì´ ê·¸ë£¹ ìˆ˜: {len(group_options)}")
    st.write(f"ì´ í‚¤ì›Œë“œ ìˆ˜: {len(master_df['KEYWORD'].unique())}")
    st.write("ê·¸ë£¹ ëª©ë¡:", group_options[:10])
    st.write("ì²« 5í–‰ ë°ì´í„°:")
    st.dataframe(master_df.head())

cols = st.columns(num_targets)

for i in range(num_targets):
    with cols[i]:
        def_label = st.session_state.active_groups.get(f"label_{i}", f"ë¹„êµêµ° {i+1}")
        def_groups = st.session_state.active_groups.get(f"groups_{i}", [])
        def_kws = st.session_state.active_groups.get(f"kws_{i}", [])

        label = st.text_input(f"ëŒ€ìƒ {i+1} ì´ë¦„", value=def_label, key=f"lab_{i}")
        
        # ê·¸ë£¹ ì„ íƒ ì—†ì„ ë•Œ ì•ˆë‚´ ë©”ì‹œì§€
        if not group_options:
            st.error("ì‚¬ìš© ê°€ëŠ¥í•œ ê·¸ë£¹ì´ ì—†ìŠµë‹ˆë‹¤. ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ë°ì´í„°ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
            continue
            
        sel_groups = st.multiselect(
            f"ê·¸ë£¹(ë¸Œëœë“œ) ì„ íƒ", 
            options=group_options, 
            default=[g for g in def_groups if g in group_options], 
            key=f"gr_{i}",
            help="ë¨¼ì € ê·¸ë£¹ì„ ì„ íƒí•˜ì„¸ìš”"
        )
        
        if sel_groups:
            kw_options = sorted([
                k for k in master_df[master_df['GROUP'].isin(sel_groups)]['KEYWORD'].unique() 
                if pd.notna(k)
            ])
            
            if not kw_options:
                st.warning("ì„ íƒí•œ ê·¸ë£¹ì— í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
                continue
                
            current_def = [k for k in def_kws if k in kw_options] if def_kws else []
            sel_kws = st.multiselect(
                f"í‚¤ì›Œë“œ ì„ íƒ", 
                options=kw_options, 
                default=current_def if current_def else kw_options[:min(3, len(kw_options))], 
                key=f"kw_{i}",
                help=f"ì„ íƒ ê°€ëŠ¥í•œ í‚¤ì›Œë“œ: {len(kw_options)}ê°œ"
            )
            
            # ë¼ë²¨ê³¼ í‚¤ì›Œë“œê°€ ëª¨ë‘ ìˆì„ ë•Œë§Œ ì¶”ê°€
            if label and label.strip() and sel_kws:
                final_filter[label] = sel_kws
                st.success(f"âœ… {len(sel_kws)}ê°œ í‚¤ì›Œë“œ ì„ íƒë¨")
        else:
            st.info("â¬†ï¸ ê·¸ë£¹ì„ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”")

# ë””ë²„ê¹…: final_filter ìƒíƒœ í‘œì‹œ
st.markdown("---")
if final_filter:
    st.success(f"âœ… ì´ {len(final_filter)}ê°œ ë¶„ì„ ëŒ€ìƒì´ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤")
    with st.expander("ì„ íƒëœ ë¶„ì„ ëŒ€ìƒ í™•ì¸"):
        for label, kws in final_filter.items():
            st.write(f"**{label}**: {len(kws)}ê°œ í‚¤ì›Œë“œ")
            st.write(", ".join(kws[:5]) + ("..." if len(kws) > 5 else ""))
else:
    st.warning("âš ï¸ ë¶„ì„ ëŒ€ìƒì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ê·¸ë£¹ê³¼ í‚¤ì›Œë“œë¥¼ ì„ íƒí•˜ì„¸ìš”.")

# --- 6. ë¶„ì„ ì‹¤í–‰ ---
if final_filter:
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        results = []
        all_unique_kws = list(set([kw for kws in final_filter.values() for kw in kws]))
        
        if len(all_unique_kws) > 50:
            st.warning(f"ì„ íƒí•œ í‚¤ì›Œë“œê°€ {len(all_unique_kws)}ê°œì…ë‹ˆë‹¤. 50ê°œ ì´í•˜ë¡œ ì¤„ì´ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        progress = st.progress(0)
        status = st.empty()
        
        # 1ë‹¨ê³„: ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
        all_vols = {}
        for i in range(0, len(all_unique_kws), 5):
            chunk = all_unique_kws[i:i+5]
            status.text(f"ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ({min(i+5, len(all_unique_kws))}/{len(all_unique_kws)})")
            chunk_vols = get_naver_search_vols_bulk(
                chunk, 
                keys["naver_api_key"], 
                keys["naver_secret_key"], 
                keys["naver_customer_id"]
            )
            all_vols.update(chunk_vols)
            progress.progress(min((i+5)/(len(all_unique_kws)*2), 0.4))
            time.sleep(0.3)

        # 2ë‹¨ê³„: íŠ¸ë Œë“œ ì¡°íšŒ
        current_idx = 0
        total_kws = len(all_unique_kws)
        
        for group_label, kws in final_filter.items():
            for kw in kws:
                current_idx += 1
                status.text(f"â³ [{group_label}] ë¶„ì„ ì¤‘: {kw} ({current_idx}/{total_kws})")
                
                vol = all_vols.get(kw, 0)
                trends = get_datalab_trend(
                    kw, 
                    keys["naver_client_id"], 
                    keys["naver_client_secret"], 
                    s_date, 
                    e_date, 
                    unit
                )
                
                if trends:
                    total_r = sum(trends.values())
                    for p, r in trends.items():
                        results.append({
                            "ë¶„ì„ëŒ€ìƒ": group_label, 
                            "ê¸°ê°„": p, 
                            "í‚¤ì›Œë“œ": kw,
                            "ê²€ìƒ‰ëŸ‰": int((r/total_r)*vol) if total_r > 0 else 0
                        })
                elif vol > 0:
                    results.append({
                        "ë¶„ì„ëŒ€ìƒ": group_label, 
                        "ê¸°ê°„": s_date.strftime("%Y-%m-%d"), 
                        "í‚¤ì›Œë“œ": kw,
                        "ê²€ìƒ‰ëŸ‰": vol
                    })
                
                progress.progress(0.4 + (current_idx / total_kws * 0.6))
                time.sleep(0.15)

        status.empty()
        progress.empty()

        if results:
            df = pd.DataFrame(results)
            df_grp = df.groupby(['ê¸°ê°„', 'ë¶„ì„ëŒ€ìƒ'])['ê²€ìƒ‰ëŸ‰'].sum().reset_index()
            
            period_totals = df_grp.groupby('ê¸°ê°„')['ê²€ìƒ‰ëŸ‰'].transform('sum')
            df_grp['ë¹„ì¤‘'] = ((df_grp['ê²€ìƒ‰ëŸ‰'] / period_totals * 100).fillna(0)).round(1)
            
            fig = px.bar(
                df_grp, 
                x="ê²€ìƒ‰ëŸ‰", 
                y="ê¸°ê°„", 
                color="ë¶„ì„ëŒ€ìƒ", 
                orientation='h', 
                barmode='stack',
                text=df_grp.apply(lambda x: f"{x['ê²€ìƒ‰ëŸ‰']:,} ({x['ë¹„ì¤‘']}%)", axis=1), 
                height=max(600, len(df_grp['ê¸°ê°„'].unique()) * 40),
                color_discrete_sequence=px.colors.qualitative.Pastel,
                title="ê¸°ê°„ë³„ ê²€ìƒ‰ëŸ‰ ë° ì ìœ ìœ¨"
            )
            fig.update_traces(textposition='inside')
            st.plotly_chart(fig, use_container_width=True)
            
            st.subheader("ğŸ“‹ ìƒì„¸ ë°ì´í„°")
            pivot_df = df.pivot_table(
                index=["ë¶„ì„ëŒ€ìƒ", "í‚¤ì›Œë“œ"], 
                columns="ê¸°ê°„", 
                values="ê²€ìƒ‰ëŸ‰", 
                aggfunc="sum",
                fill_value=0
            )
            st.dataframe(pivot_df, use_container_width=True)
            
            st.subheader("ğŸ“ˆ ìš”ì•½")
            summary = df.groupby('ë¶„ì„ëŒ€ìƒ')['ê²€ìƒ‰ëŸ‰'].sum().sort_values(ascending=False)
            st.dataframe(summary.rename("ì´ ê²€ìƒ‰ëŸ‰"), use_container_width=True)
            
        else:
            st.error("ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:")
            st.markdown("""
            - API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
            - í‚¤ì›Œë“œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            - ë‚ ì§œ ë²”ìœ„ê°€ ì ì ˆí•œì§€ í™•ì¸
            - ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
            """)
else:
    st.info("ğŸ‘† ë¶„ì„ ëŒ€ìƒì„ ì„¤ì •í•˜ê³  'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

# --- 6. ë¶„ì„ ì‹¤í–‰ ---
st.markdown("---")
if final_filter:
    if st.button("ğŸš€ ë¶„ì„ ì‹œì‘", type="primary", use_container_width=True):
        results = []
        all_unique_kws = list(set([kw for kws in final_filter.values() for kw in kws]))
        
        if len(all_unique_kws) > 50:
            st.warning(f"ì„ íƒí•œ í‚¤ì›Œë“œê°€ {len(all_unique_kws)}ê°œì…ë‹ˆë‹¤. 50ê°œ ì´í•˜ë¡œ ì¤„ì´ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
        
        progress = st.progress(0)
        status = st.empty()
        
        # 1ë‹¨ê³„: ê²€ìƒ‰ëŸ‰ ì¡°íšŒ
        all_vols = {}
        for i in range(0, len(all_unique_kws), 5):
            chunk = all_unique_kws[i:i+5]
            status.text(f"ğŸ” ë„¤ì´ë²„ ê²€ìƒ‰ëŸ‰ ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ({min(i+5, len(all_unique_kws))}/{len(all_unique_kws)})")
            chunk_vols = get_naver_search_vols_bulk(
                chunk, 
                keys["naver_api_key"], 
                keys["naver_secret_key"], 
                keys["naver_customer_id"]
            )
            all_vols.update(chunk_vols)
            progress.progress(min((i+5)/(len(all_unique_kws)*2), 0.4))
            time.sleep(0.3)  # API ë¶€í•˜ ë°©ì§€

        # 2ë‹¨ê³„: íŠ¸ë Œë“œ ì¡°íšŒ
        current_idx = 0
        total_kws = len(all_unique_kws)
        
        for group_label, kws in final_filter.items():
            for kw in kws:
                current_idx += 1
                status.text(f"â³ [{group_label}] ë¶„ì„ ì¤‘: {kw} ({current_idx}/{total_kws})")
                
                vol = all_vols.get(kw, 0)
                trends = get_datalab_trend(
                    kw, 
                    keys["naver_client_id"], 
                    keys["naver_client_secret"], 
                    s_date, 
                    e_date, 
                    unit
                )
                
                if trends:
                    total_r = sum(trends.values())
                    for p, r in trends.items():
                        results.append({
                            "ë¶„ì„ëŒ€ìƒ": group_label, 
                            "ê¸°ê°„": p, 
                            "í‚¤ì›Œë“œ": kw,
                            "ê²€ìƒ‰ëŸ‰": int((r/total_r)*vol) if total_r > 0 else 0
                        })
                elif vol > 0:
                    # íŠ¸ë Œë“œ ì—†ì§€ë§Œ ê²€ìƒ‰ëŸ‰ì´ ìˆëŠ” ê²½ìš°
                    results.append({
                        "ë¶„ì„ëŒ€ìƒ": group_label, 
                        "ê¸°ê°„": s_date.strftime("%Y-%m-%d"), 
                        "í‚¤ì›Œë“œ": kw,
                        "ê²€ìƒ‰ëŸ‰": vol
                    })
                
                progress.progress(0.4 + (current_idx / total_kws * 0.6))
                time.sleep(0.15)  # API ë¶€í•˜ ë°©ì§€

        status.empty()
        progress.empty()

        if results:
            df = pd.DataFrame(results)
            df_grp = df.groupby(['ê¸°ê°„', 'ë¶„ì„ëŒ€ìƒ'])['ê²€ìƒ‰ëŸ‰'].sum().reset_index()
            
            # ë¹„ì¤‘ ê³„ì‚° (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
            period_totals = df_grp.groupby('ê¸°ê°„')['ê²€ìƒ‰ëŸ‰'].transform('sum')
            df_grp['ë¹„ì¤‘'] = ((df_grp['ê²€ìƒ‰ëŸ‰'] / period_totals * 100).fillna(0)).round(1)
            
            # ê·¸ë˜í”„ ìƒì„±
            fig = px.bar(
                df_grp, 
                x="ê²€ìƒ‰ëŸ‰", 
                y="ê¸°ê°„", 
                color="ë¶„ì„ëŒ€ìƒ", 
                orientation='h', 
                barmode='stack',
                text=df_grp.apply(lambda x: f"{x['ê²€ìƒ‰ëŸ‰']:,} ({x['ë¹„ì¤‘']}%)", axis=1), 
                height=max(600, len(df_grp['ê¸°ê°„'].unique()) * 40),
                color_discrete_sequence=px.colors.qualitative.Pastel,
                title="ê¸°ê°„ë³„ ê²€ìƒ‰ëŸ‰ ë° ì ìœ ìœ¨"
            )
            fig.update_traces(textposition='inside')
            st.plotly_chart(fig, use_container_width=True)
            
            # ìƒì„¸ ë°ì´í„° í…Œì´ë¸”
            st.subheader("ğŸ“‹ ìƒì„¸ ë°ì´í„°")
            pivot_df = df.pivot_table(
                index=["ë¶„ì„ëŒ€ìƒ", "í‚¤ì›Œë“œ"], 
                columns="ê¸°ê°„", 
                values="ê²€ìƒ‰ëŸ‰", 
                aggfunc="sum",
                fill_value=0
            )
            st.dataframe(pivot_df, use_container_width=True)
            
            # ìš”ì•½ í†µê³„
            st.subheader("ğŸ“ˆ ìš”ì•½")
            summary = df.groupby('ë¶„ì„ëŒ€ìƒ')['ê²€ìƒ‰ëŸ‰'].sum().sort_values(ascending=False)
            st.dataframe(summary.rename("ì´ ê²€ìƒ‰ëŸ‰"), use_container_width=True)
            
        else:
            st.error("ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:")
            st.markdown("""
            - API í‚¤ê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸
            - í‚¤ì›Œë“œê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            - ë‚ ì§œ ë²”ìœ„ê°€ ì ì ˆí•œì§€ í™•ì¸ (ë„ˆë¬´ ê¸´ ê¸°ê°„ì€ í”¼í•˜ì„¸ìš”)
            - ë„¤íŠ¸ì›Œí¬ ì—°ê²° í™•ì¸
            """)
else:
    st.info("ë¶„ì„ ëŒ€ìƒì„ ì„¤ì •í•˜ê³  'ë¶„ì„ ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
